{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6dc1f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install pandas\n",
    "#!pip3 install sklearn\n",
    "#!pip3 install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbbfc7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41074ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = []\n",
    "with (open(\"all_data.pkl\", \"rb\")) as openfile:\n",
    "    while True:\n",
    "        try:\n",
    "            objects.append(pickle.load(openfile))\n",
    "        except EOFError:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "141c5630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(str(len(objects)))\n",
    "pdata=objects[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ca80a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(168, 20)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdata.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af30012f",
   "metadata": {},
   "source": [
    "#### Extract Catdef for ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86b160f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: created directory 'catdef_extraction'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_dir=\"catdef_extraction\"\n",
    "os.system(\"mkdir -v \"+extraction_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e7eb5896",
   "metadata": {},
   "outputs": [],
   "source": [
    "catdef_dims=pdata.apply(lambda row:row['catdef'].shape,axis=1).tolist()[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40c28d25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33, 37)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catdef_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1728a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row is 0 of 33 ...\n",
      "row is 1 of 33 ...\n",
      "row is 2 of 33 ...\n",
      "row is 3 of 33 ...\n",
      "row is 4 of 33 ...\n",
      "row is 5 of 33 ...\n",
      "row is 6 of 33 ...\n",
      "row is 7 of 33 ...\n",
      "row is 8 of 33 ...\n",
      "row is 9 of 33 ...\n",
      "row is 10 of 33 ...\n",
      "row is 11 of 33 ...\n",
      "row is 12 of 33 ...\n",
      "row is 13 of 33 ...\n",
      "row is 14 of 33 ...\n",
      "row is 15 of 33 ...\n",
      "row is 16 of 33 ...\n",
      "row is 17 of 33 ...\n",
      "row is 18 of 33 ...\n",
      "row is 19 of 33 ...\n",
      "row is 20 of 33 ...\n",
      "row is 21 of 33 ...\n",
      "row is 22 of 33 ...\n",
      "row is 23 of 33 ...\n",
      "row is 24 of 33 ...\n",
      "row is 25 of 33 ...\n",
      "row is 26 of 33 ...\n",
      "row is 27 of 33 ...\n",
      "row is 28 of 33 ...\n",
      "row is 29 of 33 ...\n",
      "row is 30 of 33 ...\n",
      "row is 31 of 33 ...\n",
      "row is 32 of 33 ...\n",
      "nan_counts_obs {168}\n",
      "num nan data points : 363\n"
     ]
    }
   ],
   "source": [
    "nan_counts_obs=set()\n",
    "num_nan_dps=0\n",
    "for row_idx in range(catdef_dims[0]):\n",
    "    print(f\"row is {row_idx} of {catdef_dims[0]} ...\")\n",
    "    for col_idx in range(catdef_dims[1]):\n",
    "        the_header=f\"catdef_row.{row_idx}.col.{col_idx}\"\n",
    "        csv_target=f\"{extraction_dir}/catdef.{the_header}.csv\"\n",
    "        the_data=pdata.apply(lambda row:row['catdef'].item((row_idx,col_idx)),axis=1).tolist()\n",
    "        nan_data=[d for d in the_data if np.isnan(d)]\n",
    "        num_nans=len(nan_data)\n",
    "        if(num_nans>0):\n",
    "            nan_counts_obs.add(num_nans)\n",
    "            num_nan_dps=num_nan_dps+1\n",
    "            #this means that any nan data is never written!\n",
    "            continue\n",
    "        temp_df=pd.DataFrame.from_dict({the_header:the_data})\n",
    "        temp_df.to_csv(csv_target,index=False)\n",
    "        #break\n",
    "    #break\n",
    "print(f\"nan_counts_obs {nan_counts_obs}\")\n",
    "print(f\"num nan data points : {num_nan_dps}\")\n",
    "#this shows that any series is either all-data or all-nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1713540",
   "metadata": {},
   "source": [
    "### Execution\n",
    "\n",
    "After creating the files, inside the docker container build with the R dockerfile, run the Rscript in a command like so : \n",
    "\n",
    "`\n",
    "find catdef_extraction/*.csv|grep -Piv 'preds'|awk '{ print\"./arima_train_cli.R \" $0   }' |parallel -j 6 --eta\n",
    "`\n",
    "\n",
    "Change the \"-j 6\" for parallel to be perhaps \"-j+0\" to use all the cores? or the 6 to some higher or lower value depending on the number of cores.  The command can also be run inside a \"screen\" so as to help ensure that the program's execution is not interrupted.\n",
    "\n",
    ".RData files are generated which contain the arima models and predictions for each of the 24 test periods as well as a prediction for the \"25th\" test period (Jan 2017)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bff838",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
